{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb20570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0013abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stored dataframe 'enrolled_gpas' from Feature_Engineering notebook\n",
    "%store -r enrolled_gpas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b96189",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "I wanted to see how the model is performing right now before I even gather the rest of the data and create the other features. Therefore, I went ahead and ran this preliminary LR. This is by no means my final model. My final attempts with LR with my completed features was done in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Features and response\n",
    "X = enrolled_gpas[['age', 'id', 'totcr', 'status', 'stype', 'resd_desc',\n",
    "                     'degcode', 'majr_desc1', 'gender', 'ethn_desc', 'cnty_desc1', 'styp', \n",
    "                     'resd', 'acd_std_desc', 'term_att_crhr', 'term_earn_crhr', 'term_gpa', \n",
    "                     'inst_gpa', 'inst_earned', 'inst_hrs_att', 'overall_gpa']]\n",
    "\n",
    "y = enrolled_gpas['enrolled']\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "encoder = OneHotEncoder(drop = 'first')  # 'drop' parameter is used to avoid multicollinearity\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "#X_encoded = X_encoded.toarray()\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size = 0.2, random_state = 101)\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg = LogisticRegression(max_iter = 10000)  # max_iter may need to be increased if the algorithm doesn't converge\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test_binary = (y_test == 'Enrolled').astype(int)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_binary, y_prob, pos_label = 0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color = 'darkorange', lw = 2, label = f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ceb52",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r enrolled_gpas_online_fafsa_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ed11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrolled_gpas_xgb = enrolled_gpas_online_fafsa_hs[['enrolled', 'stype', 'gender', 'ethn_desc', 'resd', 'fully_online',\n",
    "                                       'acd_std_desc', 'age', 'term_att_crhr', 'term_earn_crhr', 'term_gpa',\n",
    "                                       'inst_gpa', 'inst_earned', 'no_pell', 'pell', 'subsidized', 'unsubsidized', \n",
    "                                       'summer_plus', 'kansas_promise', 'all_fafsa', 'hs_matriculation']]\n",
    "\n",
    "# Encode 'enrolled' and 'not enrolled'\n",
    "enrolled_gpas_xgb['enrolled'] = [1 if i == 'Enrolled' else 0 for i in enrolled_gpas_xgb['enrolled']]\n",
    "\n",
    "# Check to make sure the 1 and 0 correspond to enrolled/not enrolled\n",
    "#list(zip(list(enrolled_gpas_xgb['enrolled']), list(enrolled_gpas['enrolled'])))\n",
    "\n",
    "# Filter out 'Z' from 'resd' (2 observations)\n",
    "enrolled_gpas_xgb = enrolled_gpas_xgb[enrolled_gpas_xgb['resd'] != 'Z']\n",
    "\n",
    "# Change NaN values in hs_matriculation to 'Not From HS'\n",
    "enrolled_gpas_xgb['hs_matriculation'] = enrolled_gpas_xgb['hs_matriculation'].fillna('Not From HS')\n",
    "\n",
    "# Filter out students over 60 and below the age of 10. This eliminates 123 over 60 and 3 below\n",
    "# the age of 10. The three below the age of ten are obviously mistakes, two are below the age of 1\n",
    "# and one is exactly two years old. The over 60 is almost entirely made up of current staff or \n",
    "# faculty, spouses, or previous faculty, staff, or spouses.\n",
    "enrolled_gpas_xgb = enrolled_gpas_xgb[(enrolled_gpas_xgb['age'] <= 60) & (enrolled_gpas_xgb['age'] >= 10)]\n",
    "\n",
    "enrolled_gpas_xgb = enrolled_gpas_xgb[enrolled_gpas_xgb['ethn_desc'] != 'DO NOT USE - Hispanic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadf038",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enrolled_gpas_xgb.drop('enrolled', axis = 1)\n",
    "y = enrolled_gpas_xgb['enrolled'] # response variable\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdaa45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'object':\n",
    "        X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "        X_test[col] = le.transform(X_test[col].astype(str))\n",
    "\n",
    "# Create XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic', seed=101)\n",
    "\n",
    "# Define hyperparameters for GridSearchCV\n",
    "params = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to select best hyperparameters\n",
    "grid_search = GridSearchCV(xgb_clf, param_grid=params, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Fit XGBoost classifier with best hyperparameters\n",
    "best_xgb_clf = grid_search.best_estimator_\n",
    "best_xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = best_xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy on test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98515f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fitting GridSearchCV\n",
    "best_hyperparams = grid_search.best_params_\n",
    "print(\"Best hyperparameters: \\n\", best_hyperparams, '\\n')\n",
    "\n",
    "# Best score achieved during the grid search\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best accuracy score from GridSearchCV:\\n\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6991d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy calculated by hand\n",
    "np.sum([cm[0,0],cm[1,1]]) / np.sum([cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.best_estimator_\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "\n",
    "# Calculate precision, recall, and F1-Score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "# Print the results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Specificity:', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588995ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = best_xgb_clf.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Sort feature importance in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [features[i] for i in indices]\n",
    "\n",
    "# create plot\n",
    "plt.figure()\n",
    "\n",
    "# create plot title\n",
    "plt.title('XGBoost Feature Importance')\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation = 90)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importance = pd.DataFrame.from_dict(dict(zip(names, list(importances[indices]))), orient = 'index')\\\n",
    "                   .reset_index()\\\n",
    "                   .rename(columns = {'index':'Variables',\n",
    "                                       0:'Importance'})\n",
    "\n",
    "xgb_importance['Cumsum_Importance'] = np.cumsum(xgb_importance['Importance'])\n",
    "\n",
    "xgb_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6316ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame.from_dict(dict(zip(names, list(importances[indices]))), orient = 'index')\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns = {'index':'Features',\n",
    "                            0:'Importance'})\n",
    "\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# compute ROC curve and ROC area for each clcass\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute precision-recall curve and average precision for each class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Compute the AUC for the precision-recall curve\n",
    "PrecRec_auc = auc(recall, precision)\n",
    "print('The AUC for the Precision-Recall Curve is ', round(PrecRec_auc, 5) * 100,\n",
    "      '%.\\n',\n",
    "      'While the AUC for the AUC for the ROC is ', round(roc_auc, 5) * 100,\n",
    "      '%.', sep = '')\n",
    "\n",
    "#plot ROC curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color = 'darkorange', lw = lw, label = 'ROC curve (area = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color = 'navy', lw = lw, linestyle = '--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characterisitic')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color = 'darkorange', lw = lw, label = 'Precision-Recall curve (AUC = %0.4f)' % PrecRec_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b574c",
   "metadata": {},
   "source": [
    "# XGBoost Regressor\n",
    "\n",
    "The second part of this modeling for the VPA is to take the ML prediction of which students who are most likely to *not* reenroll from Fall to Fall (i.e. *specificity*) and assess how the credit hour enrollment would change if different percentages of these students *were* retained. The only way we can really do that is be examining the students who *do* retain and creating a model that predicts how many credit hours those students will enroll in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ffec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create XGBRegressor object\n",
    "xg_reg = xgb.XGBRegressor(objective = 'reg:squarederror')\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid = GridSearchCV(estimator = xg_reg, param_grid = param_grid, scoring = 'neg_mean_squared_error', cv = 5, verbose = 1)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid.fit(X_train2, y_train2)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "y_pred = grid.best_estimator_.predict(X_test2)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test2, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assume y_test are the true values and y_pred are the predictions from the model\n",
    "r2 = r2_score(y_test2, y_pred)\n",
    "\n",
    "# Number of observations\n",
    "n = len(y_test2)\n",
    "\n",
    "# Number of predictors. X_train.shape[1] gives the number of features used to train the model.\n",
    "p = X_train2.shape[1]\n",
    "\n",
    "# Adjusted R-squared calculation\n",
    "r2_adj = 1 - (1-r2) * (n-1)/(n-p-1)\n",
    "\n",
    "print(\"R-squared: \", r2)\n",
    "print(\"Adjusted R-squared: \", r2_adj, '\\n')\n",
    "\n",
    "# Get feature importance\n",
    "importance = grid.best_estimator_.feature_importances_\n",
    "\n",
    "# Retrieve feature names\n",
    "feature_names = X_train2.columns\n",
    "\n",
    "# Combine feature names and their importance scores\n",
    "feature_importance_dict = dict(zip(feature_names, importance))\n",
    "\n",
    "# store feature importance\n",
    "importance_dict = {}\n",
    "for feature, score in feature_importance_dict.items():\n",
    "    importance_dict[feature] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame.from_dict(importance_dict, orient = 'index')\n",
    "   .reset_index()\n",
    "   .rename(columns = {'index':'variable',\n",
    "                       0:'importance'})\n",
    "   .sort_values('importance', ascending = False)\n",
    "   .reset_index(drop = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort the features by importance\n",
    "sorted_importances = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Unzip into two lists\n",
    "sorted_features, sorted_scores = zip(*sorted_importances)\n",
    "\n",
    "# Create a bar chart\n",
    "plt.barh(sorted_features, sorted_scores)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importances')\n",
    "\n",
    "# Invert y-axis to have the most important feature on top\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b30088d",
   "metadata": {},
   "source": [
    "### Test Every Classifier\n",
    "\n",
    "Ok, so this is not *every* classifier, but it is damn close. This is something I came across through Akshay Pachaar. He posted this to Twitter on 11.1.23 and I just had to try it. Lazy Predict ran through all of these models in just a few minutes. With hyperparamter tuning in my XGBoost model, I get an accuracy of 0.7504, which is marginally better than a non-hyperparamter tuned model. LGBM performs the absolute best.\n",
    "\n",
    "If I want to use regression, you just import *LazyRegressor* and code:\n",
    "\n",
    "```{python}\n",
    "\n",
    "reg = LazyRegressor(verbose = 0, ignore_warnings = False, custom_metric = None)\n",
    "\n",
    "models = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "models\n",
    "\n",
    "```\n",
    "\n",
    "This will produce a table with the following columns:\n",
    "\n",
    "|**Model** | **Adjusted R-Squ**| **R-Squared** | **RMSE** | **Time Taken**|\n",
    "|:---------|------------------:|--------------:|---------:|--------------:|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X2 = only_enrolled.drop('term_att_crhr', axis = 1)\n",
    "y2 = only_enrolled['term_att_crhr'] # response variable\n",
    "\n",
    "# split the data\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.2)\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in X_train2.columns:\n",
    "    if X_train2[col].dtype == 'object':\n",
    "        X_train2[col] = le.fit_transform(X_train2[col].astype(str))\n",
    "        X_test2[col] = le.transform(X_test2[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"only_enrolled\" object is actually below in the \"Test Every Classifier\" \n",
    "# section. So that needs to be run first.\n",
    "X2 = only_enrolled.drop('term_att_crhr', axis = 1)\n",
    "y2 = only_enrolled['term_att_crhr'] # response variable\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in X2.columns:\n",
    "    if X2[col].dtype == 'object':\n",
    "        X2[col] = le.fit_transform(X2[col].astype(str))\n",
    "        \n",
    "enrolled_pred = grid.best_estimator_.predict(X2)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y2, enrolled_pred))\n",
    "\n",
    "print('RMSE: %f' % (rmse))\n",
    "\n",
    "# Add prediction and original value column\n",
    "X2['prediction'], X2['term_att_crhr'] = enrolled_pred, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50868a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column name in the test set (X2)\n",
    "X2 = X2.rename(columns = {'term_att_crhr':'original_val'})\n",
    "\n",
    "# Store as Data Frame\n",
    "pd.concat([only_enrolled, X2[['prediction', 'original_val']]], axis = 1).to_csv('Enrolled Predictions FA19-FA22.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa658b1f",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3066f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Identify categorical columns that need encoding\n",
    "categorical_features = ['stype', 'gender', 'ethn_desc', 'resd', 'acd_std_desc', 'fully_online', 'hs_matriculation']\n",
    "\n",
    "# Create a column transformer to encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# Create SVM model with a linear kernel (you can choose another kernel like 'rbf' if needed)\n",
    "svm_model = SVC(kernel='linear', probability = False)\n",
    "\n",
    "# Make a pipeline that includes preprocessing and the classifier\n",
    "pipeline = make_pipeline(preprocessor, svm_model)\n",
    "\n",
    "# Perform ten-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"10-fold cross-validation accuracy scores:\", cross_val_scores)\n",
    "print(\"Mean CV Accuracy:\", np.mean(cross_val_scores))\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Calculate precision, recall, F1-score, and specificity\n",
    "report = classification_report(y_test, y_pred, target_names=['Not Enrolled', 'Enrolled'])\n",
    "print(report)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Specificity is just the true negative rate\n",
    "tp, fp, fn, tn = conf_matrix.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity:\", specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the scores\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(cross_val_scores, marker = 'o', linestyle = '-', color = 'b')\n",
    "plt.title('Cross-validation scores')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(len(cross_val_scores)), [f\"Fold {i+1}\" for i in range(len(cross_val_scores))])\n",
    "plt.show()\n",
    "\n",
    "# create a box plot to show the distribution of scores across the folds\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(cross_val_scores, vert = True, patch_artist = True)\n",
    "plt.title('Cross-validation scores distribution')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = pipeline.named_steps['svc']\n",
    "\n",
    "coefficients = svm_classifier.coef_.flatten()\n",
    "\n",
    "# Get the feature names after one-hot encoding\n",
    "feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "feature_names = np.concatenate([feature_names, X_train.columns.difference(categorical_features)])\n",
    "\n",
    "# Create a DataFrame with the feature names and their corresponding coefficients\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': coefficients})\n",
    "\n",
    "# Sort the DataFrame based on the absolute values of the importance score\n",
    "feature_importance = feature_importance.reindex(feature_importance.Importance.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Create the lollipop plot - horizontal\n",
    "plt.figure(figsize=(10, 8))  # Adjust the figure size as needed\n",
    "plt.hlines(y=feature_importance['Feature'], xmin=0, xmax=feature_importance['Importance'], color='dodgerblue')\n",
    "plt.scatter(feature_importance['Importance'], feature_importance['Feature'], color='darkorange')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Variable Importance of SVM')\n",
    "plt.grid(False)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
