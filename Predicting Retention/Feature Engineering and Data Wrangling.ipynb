{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cceb724d",
   "metadata": {},
   "source": [
    "### Housekeeping \n",
    "\n",
    "For Fall 2019, 2020, 2021, and 2022, we had student data from the IR database for Day 1, 20th-Day, and EOT. I downloaded all three recordings of students and then eliminated the duplicates by student ID. The reason I chose to do this rather than the more traditional way in the research, which is usually Day 1 to Day 1 or 20th-Day to 20th-Day is because I want as complete a picture as possible of the students who persist from one Fall to the next. Most research focuses on First Time-Full Time, which is the IPEDs data. On a practical level, we are interested in what predictors help us predict all of the students who reenroll from one semester to the next. For Fall 2023, since we do not have all three sets, I downloaded the data from Argos as well as the Day 1 data from the IR database and eliminated duplicate IDs. By the time I finish the report, we will have 20th-Day numbers. I will incorporate those in and that will be the best I can do for this semester.\n",
    "\n",
    "The following attributes were used in the analysis:\n",
    "\n",
    "* Earned_sem_crhr\n",
    "* Tot_inst_hrs\n",
    "* term_gpa\n",
    "* inst_gpa\n",
    "* pell/no_pell\n",
    "* scholarship\n",
    "* ethnicity\n",
    "* age\n",
    "* distance (long, lat: Haversine Formula)\n",
    "* Stype\n",
    "* attempted hours\n",
    "* interaction term (earned/att = completion ratio)\n",
    "* fully online vs. not fully online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import ipytest\n",
    "\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(exist_ok=True)\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\"])\n",
    "\n",
    "file_path = ['Files/', ' Enrollment.csv']\n",
    "file_path_gpa = ['Files/', ' GPA and CrHrs.csv']\n",
    "\n",
    "semesters = ['201980', '202080', '202180', '202280', '202380']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all semesters' enrollment\n",
    "\n",
    "all_sems = []\n",
    "for i in semesters:\n",
    "    temp = pd.read_csv(file_path[0] + i + file_path[1])\n",
    "    temp.columns = [i.lower() for i in temp.columns]\n",
    "    all_sems.append(temp)\n",
    "    \n",
    "all_sems = (pd.concat(all_sems)\n",
    "              .reset_index(drop = True)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the gpa and attempted/earned credit hour datasets\n",
    "all_gpas = []\n",
    "\n",
    "for i in semesters[:4]:\n",
    "    temp = (pd.read_csv(file_path_gpa[0] + i + file_path_gpa[1])\n",
    "              .rename(columns = str.lower))\n",
    "    all_gpas.append(temp)\n",
    "\n",
    "all_gpas = (pd.concat(all_gpas).reset_index(drop = True)\n",
    "              .rename(columns = {'studentid':'id',\n",
    "                                 'gpatrm':'term'})\n",
    "           )\n",
    "\n",
    "# There was one single row out of 30000 that had NaN values so \n",
    "# I filtered it out.\n",
    "all_gpas = all_gpas[all_gpas['term'].isna() == False]\n",
    "\n",
    "all_gpas['term'] = all_gpas['term'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466bd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pell Grant and Load information\n",
    "pell = (pd.read_csv(file_path[0] + 'Pell and Loan FA19 - FA23.csv')\n",
    "          .rename(columns = {'LOAN_GRANT_TERM':'term'})\n",
    "          .rename(columns = str.lower)\n",
    "       )\n",
    "\n",
    "# Sort dataframe\n",
    "pell = pell.sort_values(['term', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import select_sem, find_enrolled\n",
    "\n",
    "# Make list of years\n",
    "sems_filt = [19, 20, 21, 22, 23]\n",
    "\n",
    "# Loop through each semester to compare them to one another and \n",
    "# record who enrolled from one semester to the next.\n",
    "perc_enrolled = []\n",
    "all_enrolled = []\n",
    "\n",
    "for i in range(1, 5, 1):\n",
    "    temp_perc = find_enrolled(select_sem(all_sems, int(semesters[i-1])), \n",
    "                         select_sem(all_sems, int(semesters[i])), \n",
    "                         sems_filt[i - 1], sems_filt[i])[0]\n",
    "    temp_enrolled = find_enrolled(select_sem(all_sems, int(semesters[i-1])), \n",
    "                         select_sem(all_sems, int(semesters[i])), \n",
    "                         sems_filt[i - 1], sems_filt[i])[1]\n",
    "    perc_enrolled.append(temp_perc)\n",
    "    all_enrolled.append(temp_enrolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8197d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.concat(perc_enrolled)\n",
    "   .pivot_table(index = 'terms', columns = 'enrolled', values = ['cnt', 'percent'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5102ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the all semesters of with the enrolled/unenrolled students in it\n",
    "all_enrolled_df = (pd.concat(all_enrolled)\n",
    "                     .reset_index(drop = True)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e380d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframe with the student data and enrollment status along\n",
    "# with the gpas and credit hour data\n",
    "enrolled_gpas = all_enrolled_df.merge(all_gpas, how = 'left', on = ['id', 'term'])\n",
    "\n",
    "# There are some missing values from students who did not make it to the EOT and therefore\n",
    "# do not have GPAs. The code below is to see who those students are and to determine if \n",
    "# eliminiating them is going to severly skew the data.\n",
    "temporary_df = (pd.DataFrame(enrolled_gpas[enrolled_gpas['overall_gpa'].isna()].groupby(['term', 'enrolled'])['id'].count())\n",
    "                 .reset_index()\n",
    "                 .rename(columns = {'id':'cnt'})\n",
    "               )\n",
    "\n",
    "ls = []\n",
    "for i in temporary_df['term'].unique():\n",
    "    temp = temporary_df[temporary_df['term'] == i]\n",
    "    ls.append(temp['cnt']/temp['cnt'].sum())\n",
    "    \n",
    "\n",
    "temporary_df['percent'] = list(pd.concat(ls))\n",
    "\n",
    "# now, the dataframe after removing the missing values\n",
    "# This allows me to compare the two and see how the distribution\n",
    "# changed. If it changed significantly, I will need to examine them\n",
    "# more fully.\n",
    "more_temporary = (pd.DataFrame(enrolled_gpas[enrolled_gpas['overall_gpa'].isna()==False].groupby(['term', 'enrolled'])['id'].count())\n",
    "                   .reset_index()\n",
    "                   .rename(columns = {'id':'cnt'})\n",
    "                 )\n",
    "\n",
    "more_temporary_ls = []\n",
    "for i in temporary_df['term'].unique():\n",
    "    temp = more_temporary[more_temporary['term'] == i]\n",
    "    more_temporary_ls.append(temp['cnt']/temp['cnt'].sum())\n",
    "    \n",
    "more_temporary['percent'] = list(pd.concat(more_temporary_ls))\n",
    "\n",
    "more_temporary.pivot_table(index = 'term', columns = 'enrolled', values = ['cnt', 'percent'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c2534",
   "metadata": {},
   "source": [
    "### Comparison of the distribution of enrolled vs not enrolled\n",
    "\n",
    "This compares the distributions before I added the gpa dataset and after. After I merged the two, there were missing values. This shows how it alters the distribution if I just remove the missing values. It slightly elevates the enrolled while slightly lowering the unenrolled.\n",
    "\n",
    "**Table 1**\n",
    "|**terms**|**Enrolled**|**Not Enrolled**|**Enrolled**|**Not Enrolled**|\n",
    "|:--------|-----------:|---------------:|-----------:|---------------:|\n",
    "|fa19_fa20| \t3296| \t5139| \t0.390753| \t0.609247|\n",
    "|fa20_fa21| \t3031| \t4628| \t0.395744| \t0.604256|\n",
    "|fa21_fa22| \t2984| \t4502| \t0.398611| \t0.601389|\n",
    "|fa22_fa23| \t2770| \t4354| \t0.388827| \t0.611173|\n",
    "\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "**Table 2**\n",
    "        \n",
    "|**term**|**Enrolled**|**Not Enrolled**|**Enrolled**|**Not Enrolled**|\n",
    "|:-------|-----------:|---------------:|-----------:|---------------:|\n",
    "|201980| \t3245| \t4781| \t0.404311| \t0.595689|\n",
    "|202080| \t2965| \t4329| \t0.406498| \t0.593502|\n",
    "|202180| \t2931| \t4165| \t0.413050| \t0.586950|\n",
    "|202280| \t2710| \t4058| \t0.400414| \t0.599586|\n",
    "\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "**Table 3**\n",
    "\n",
    "|**term**|**Enrolled**|**Not Enrolled**|**Enrolled**|**Not Enrolled**|\n",
    "|:-------|-----------:|---------------:|-----------:|---------------:|\n",
    "|201980|\t3229| \t4749|\t0.404738| \t0.595262|\n",
    "|202080| \t2897| \t4256| \t0.405005| \t0.594995|\n",
    "|202180| \t2912| \t4137| \t0.413108| \t0.586892|\n",
    "|202280| \t2697| \t4040| \t0.400327| \t0.599673|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ac6cb",
   "metadata": {},
   "source": [
    "### Creating Final Dataset For Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize the columns to \n",
    "enrolled_gpas = enrolled_gpas[['term', 'pidm', 'age', 'id', 'totcr', 'status', 'stype', 'resd_desc',\n",
    "                               'degcode', 'majr_desc1', 'gender', 'mrtl', 'ethn_desc', 'cnty_desc1',\n",
    "                               'styp', 'resd', 'acd_std_desc', 'term_att_crhr', 'term_earn_crhr', \n",
    "                               'term_gpa', 'inst_gpa', 'inst_earned', 'inst_hrs_att', 'overall_gpa',\n",
    "                               'enrolled']]\n",
    "\n",
    "# Remove NaN values\n",
    "enrolled_gpas = enrolled_gpas[enrolled_gpas['overall_gpa'].isna() == False].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a406f1",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look over missing values. I made the foolish mistake when I was first downloading the data\n",
    "# to label missing values as'Not Enrolled'.\n",
    "d = {}\n",
    "for i in enrolled_gpas.columns:\n",
    "    temp = enrolled_gpas[enrolled_gpas[i] == 'Not Enrolled']\n",
    "    d[i] = (len(temp)/len(enrolled_gpas)) * 100\n",
    "\n",
    "(pd.DataFrame.from_dict(d, orient = 'index')\n",
    "   .reset_index().rename(columns = {'index':'col_names',\n",
    "                                    0:'percent_missing'})\n",
    ")\n",
    "\n",
    "output = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6460e3",
   "metadata": {},
   "source": [
    "### Evaluating Missing Data.\n",
    "\n",
    "As has been the case with other student data I have evalulated through the years for Butler, the *marital* data continues to be woefully lacking, to the extent that it is unusable in any real sense. That attribute will be removed. The *gender* column is missing $\\frac{1}{100}^{th}$ of a percent. I will just delete those values. *County* data is missing $\\frac{9}{10}^{ths}$ of one percent, so that will be removed as well. Finally, *ethnicity* is missing 6.4453%, which is congruent with previous analysis. I will impute a new attribute there simply labeled, \"missing.\"\n",
    "\n",
    "|**col_names**|**percent_missing**|\n",
    "|:------------|------------------:|\n",
    "|term| \t0.000000|\n",
    "|pidm| \t0.000000|\n",
    "|age |\t0.000000|\n",
    "|id |   0.000000|\n",
    "|totcr \t|0.000000|\n",
    "|status |\t0.000000|\n",
    "|stype \t|0.000000|\n",
    "|resd_desc| \t0.000000|\n",
    "|degcode |\t0.000000|\n",
    "|majr_desc1| \t0.000000|\n",
    "|gender |\t0.010280|\n",
    "|mrtl \t|51.117050|\n",
    "|ethn_desc| \t6.445312|\n",
    "|cnty_desc1| \t0.904605|\n",
    "|styp \t|0.000000|\n",
    "|resd \t|0.000000|\n",
    "|acd_std_desc| \t0.000000|\n",
    "|term_att_crhr| \t0.000000|\n",
    "|term_earn_crhr| \t0.000000|\n",
    "|term_gpa \t|0.000000|\n",
    "|inst_gpa \t|0.000000|\n",
    "|inst_earned |\t0.000000|\n",
    "|inst_hrs_att |\t0.000000|\n",
    "|overall_gpa |\t0.000000|\n",
    "|enrolled |\t59.392133|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d32f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'mrtl' column\n",
    "enrolled_gpas = enrolled_gpas[['term', 'pidm', 'age', 'id', 'totcr', 'status', 'stype', 'resd_desc',\n",
    "                               'degcode', 'majr_desc1', 'gender', 'ethn_desc', 'cnty_desc1', 'styp', \n",
    "                               'resd', 'acd_std_desc', 'term_att_crhr', 'term_earn_crhr', 'term_gpa', \n",
    "                               'inst_gpa', 'inst_earned', 'inst_hrs_att', 'overall_gpa', 'enrolled']]\n",
    "\n",
    "# Remove missing 'gender' and 'cnty_desc1' values\n",
    "enrolled_gpas = enrolled_gpas[enrolled_gpas['gender'] != 'Not Enrolled']\n",
    "enrolled_gpas = enrolled_gpas[enrolled_gpas['cnty_desc1'] != 'Not Enrolled']\n",
    "\n",
    "# Impute missing values in 'ethn_desc' with the attribute 'Missing'\n",
    "enrolled_gpas['ethn_desc'] = enrolled_gpas['ethn_desc'].replace('Not Enrolled', 'Missing')\n",
    "\n",
    "# Take another look at the data to make sure there are no more missing values\n",
    "d = {}\n",
    "for i in enrolled_gpas.columns:\n",
    "    temp = enrolled_gpas[enrolled_gpas[i] == 'Not Enrolled']\n",
    "    d[i] = (len(temp)/len(enrolled_gpas)) * 100\n",
    "\n",
    "(pd.DataFrame.from_dict(d, orient = 'index')\n",
    "   .reset_index().rename(columns = {'index':'col_names',\n",
    "                                    0:'percent_missing'})\n",
    ")\n",
    "\n",
    "output = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the final distribution of enrolled/not enrolled to see how it has been altered by\n",
    "# eliminating the NaNs. This was put up with the other two tables as \"Table 3\"\n",
    "more_temporary = pd.DataFrame(enrolled_gpas.groupby(['term', 'enrolled'])['id'].count())\\\n",
    "                   .reset_index()\\\n",
    "                   .rename(columns = {'id':'cnt'})\n",
    "\n",
    "more_temporary_ls = []\n",
    "for i in temporary_df['term'].unique():\n",
    "    temp = more_temporary[more_temporary['term'] == i]\n",
    "    more_temporary_ls.append(temp['cnt']/temp['cnt'].sum())\n",
    "    \n",
    "more_temporary['percent'] = list(pd.concat(more_temporary_ls))\n",
    "\n",
    "more_temporary.pivot_table(index = 'term', columns = 'enrolled', values = ['cnt', 'percent'])\n",
    "\n",
    "Output = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store enrolled_gpas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9176b3",
   "metadata": {},
   "source": [
    "# Online Classes Online\n",
    "The section below is to identify students who took all online classes as designated by their location data rather than by what they claimed on their enrollment form with the registrar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FA19 - FA22\n",
    "fa19_fa22 = (pd.read_csv('FA19 - FA22 CrHr Enrollment.csv')\n",
    "               .rename(columns = str.lower)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69727f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import count_online_classes\n",
    "\n",
    "# Loop through all the previous Fall semesters and\n",
    "# use the count_online_classes() function\n",
    "all_sems_online = []\n",
    "\n",
    "for i in [201980, 202080, 202180, 202280]:\n",
    "    temp = count_online_classes(fa19_fa22, i)\n",
    "    all_sems_online.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe of the terms with their counts of fully online and not fully online\n",
    "fully_online_cnts = (pd.DataFrame(pd.concat(all_sems_online).reset_index(drop = True).groupby(['term', 'fully_online'])['id'].count())\n",
    "                       .reset_index()\n",
    "                       .rename(columns = {'id':'count'})\n",
    "                    )\n",
    "fully_online_cnts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8687e12",
   "metadata": {},
   "source": [
    "I went through several of these through SFASRPO to make sure the count of classes was correct as well as the number of clases that were online and the percentage that represented of the ovarll total. It all checks out. So now it needs to be incorporated back into the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c53288",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all_sems_online)[:50]\n",
    "\n",
    "output = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull together all semesters' fully online data\n",
    "fully_online = pd.concat(all_sems_online).reset_index(drop = True)\n",
    "\n",
    "# Isolatejust the columns I need\n",
    "fully_online = fully_online[['id', 'term', 'fully_online']]\n",
    "\n",
    "# Merge enrolled_gpas and fully_online datasets\n",
    "enrolled_gpas_online = enrolled_gpas.merge(fully_online, how = 'left', on = ['id', 'term'])\\\n",
    "                       [['term', 'pidm', 'age', 'id', 'totcr', 'status', 'stype', 'resd_desc',\n",
    "                        'degcode', 'majr_desc1', 'gender', 'ethn_desc', 'cnty_desc1', 'styp',\n",
    "                        'resd', 'acd_std_desc', 'term_att_crhr', 'term_earn_crhr', 'term_gpa',\n",
    "                        'inst_gpa', 'inst_earned', 'inst_hrs_att', 'overall_gpa', 'fully_online',\n",
    "                        'enrolled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrolled_gpas_online\n",
    "\n",
    "output = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496f932",
   "metadata": {},
   "source": [
    "# Pell Grant and Loans\n",
    "\n",
    "One of the things that was unexpected was how many different offerings students have. The maximum number of FAFSA offerings between scholarships, loands, and grants for a single student was 12. There was one student for all five Fall semesters I am looking at that had 12 FAFSA offerings. The average number of FAFSA offers is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "pell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a80cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pell['term'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1751a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of FAFSA offerings, a count of scholarships, pell, and loans\n",
    "# offered to each student\n",
    "\n",
    "d = {}\n",
    "\n",
    "for i in pell['term'].unique():\n",
    "    temp = pell[pell['term'] == i]\n",
    "    for j in temp['id'].unique():\n",
    "        temp2 = temp[temp['id'] == j]\n",
    "        d[str(i) + j] = len(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fafsa_count = (pd.DataFrame.from_dict(d, orient = 'index')\n",
    "                 .reset_index()\n",
    "                 .rename(columns = {'index':'term_id',\n",
    "                                    0:'count_of_fafsa'})\n",
    "              )\n",
    "    \n",
    "(fafsa_count[fafsa_count['count_of_fafsa'] >= fafsa_count['count_of_fafsa'].max() - 1]\n",
    "    .reset_index(drop = True)\n",
    "    .sort_values('count_of_fafsa', ascending = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a41dc8",
   "metadata": {},
   "source": [
    "## Accepted FAFSA Monies\n",
    "\n",
    "Crucially, I didn't want to count FAFSA offered that does not get accepted. I determined this by filtering the 'accepted amount' by all the values that are not zero and filtering only thosse that had a 'paid date' that was not *NaN*. This leaves me with all the values that are non-zero and were accepted. When I did this, the top number of Fafsa awards was 10 in 202380 and 9 for 201980, 202080, 202180, and 202280. By using this selection process, the number of possible FAFSA awards over the five years dropped from 91436 to 41312, a difference of 50124.\n",
    "\n",
    "I also created a new column name called *all_fafsa* that is a sum across the row of each *id* for each *term* of awarded financial aid. This variable counts the total number of pell grants, loans, and scholarships a student has for each semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pell['accept_amt'] = pell['accept_amt'].fillna(0).astype(int)\n",
    "\n",
    "# Filter only those that had a pay out date\n",
    "pell_mask1 = pell['paid_date'].isna() == False\n",
    "\n",
    "# Filter only those that had a monetary payout\n",
    "pell_mask2 = pell['accept_amt'] != 0.00\n",
    "\n",
    "# Use filters to create the accepted FAFSA\n",
    "pell_accepted = pell[pell_mask1 & pell_mask2].reset_index(drop = True)\n",
    "\n",
    "print('The length of the \"pell\" dataframe verses the \"pell_accepted\" dataframe is:\\n',\n",
    "      \"'pell': \", len(pell), '\\n',\n",
    "      \"'pell_accepted': \", len(pell_accepted), '\\n',\n",
    "      \" Difference: \", len(pell) - len(pell_accepted), sep = \"\")\n",
    "\n",
    "pell_accepted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for each level of the pell_nopell column\n",
    "\n",
    "dummies = []\n",
    "\n",
    "for i in pell_accepted['term'].unique():\n",
    "    # Create temporary DF for each term\n",
    "    temp = pell_accepted[pell_accepted['term'] == i]\n",
    "    \n",
    "    # Convert each semester's 'pell_nopell' column to indicator variables\n",
    "    temp_dummies = pd.get_dummies(temp['pell_nopell'])\n",
    "    \n",
    "    # Combine the id and term with the dummy variables\n",
    "    temp_final = pd.concat([temp[['id', 'term']], temp_dummies], axis = 1)\n",
    "    \n",
    "    # Groupby 'id' and 'term' and sum\n",
    "    grouped_by_id_term = temp_final.groupby(['id', 'term']).sum().reset_index()\n",
    "    \n",
    "    # Do the summing process and last time with the groupby function\n",
    "    temp_final = grouped_by_id_term.groupby('id').sum().reset_index()\n",
    "    \n",
    "    # Save the temp_final to dummies list\n",
    "    dummies.append(temp_final)\n",
    "    \n",
    "# Concatenate dummies list\n",
    "final_pell = pd.concat(dummies).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Summer Plus and Kansas Promise to integers\n",
    "final_pell['Summer Plus'], final_pell['Kansas Promise'] = final_pell['Summer Plus'].astype(int), final_pell['Kansas Promise'].astype(int)\n",
    "\n",
    "# Create a column that totals all the aid offered (note this is not accepted and received FinAid, just offered FA)\n",
    "cols_to_sum = ['NO PELL', 'PELL', 'Subsidized', 'Unsubsidized', 'Summer Plus', 'Kansas Promise']\n",
    "\n",
    "# Sum all accepted FAFSA money for each ID each semester\n",
    "final_pell['all_fafsa'] = final_pell[cols_to_sum].sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the 'NO PELL' values in the column to either 1 or 0\n",
    "final_pell['NO PELL'] = [1 if i >= 1 else 0 for i in final_pell['NO PELL']]\n",
    "\n",
    "# View final pell\n",
    "final_pell = final_pell.reset_index(drop = True)\n",
    "\n",
    "final_pell.groupby('term')['id'].count(), enrolled_gpas_online.groupby('term')['id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e99cb2",
   "metadata": {},
   "source": [
    "### Combine the enrolled_gpas_online dataframe with the final_pell dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge fafsa dataframe with enrolled_gpas_online dataframe\n",
    "enrolled_gpas_online_fafsa = (enrolled_gpas_online.merge(final_pell, how = 'left', on = ['id', 'term'])\n",
    "                                  .rename(columns = {'Summer Plus':'summer_plus',\n",
    "                                                     'Kansas Promise':'kansas_promise',\n",
    "                                                     'NO PELL':'no_pell'})\n",
    "                             )\n",
    "\n",
    "# Loop thrugh the FAFSA columns and fill all NaN values with 0 and make \n",
    "# column into integer\n",
    "fafsa_cols = list(enrolled_gpas_online_fafsa.columns[25:])\n",
    "\n",
    "for i in fafsa_cols:\n",
    "    enrolled_gpas_online_fafsa[i] = enrolled_gpas_online_fafsa[i].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrolled_gpas_online_fafsa = enrolled_gpas_online_fafsa[['term', 'pidm', 'age', 'id', 'totcr', 'status', 'stype', 'resd_desc',\n",
    "                               'degcode', 'majr_desc1', 'gender', 'ethn_desc', 'cnty_desc1', 'styp',\n",
    "                               'resd', 'acd_std_desc', 'term_att_crhr', 'term_earn_crhr', 'term_gpa',\n",
    "                               'inst_gpa', 'inst_earned', 'inst_hrs_att', 'overall_gpa',\n",
    "                               'fully_online', 'no_pell', 'PELL', 'Subsidized',\n",
    "                               'Unsubsidized', 'summer_plus', 'kansas_promise', 'all_fafsa', 'enrolled']]\n",
    "\n",
    "enrolled_gpas_online_fafsa.columns = [i.lower() for i in enrolled_gpas_online_fafsa.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(enrolled_gpas_online_fafsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a129c55",
   "metadata": {},
   "source": [
    "### Add In Matriculated High School Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51295830",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_file_path = 'C:/pathway to high school data for Dean Streeter/Files/'\n",
    "\n",
    "# Load Data\n",
    "semesters = [201980, 202080, 202180, 202280, 202380]\n",
    "\n",
    "all_sems = []\n",
    "for sem in semesters:\n",
    "    temp = pd.read_csv(hs_file_path + str(sem) + ' Demographic Data.csv')\n",
    "    all_sems.append(temp)\n",
    "    \n",
    "# Combine semesters\n",
    "all_hs = pd.concat(all_sems).reset_index(drop = True)\\\n",
    "                   .rename(columns = {'STDTID':'ID',\n",
    "                                      'TERMENTERED':'TERM'})\n",
    "\n",
    "# Make all columns lowercase\n",
    "all_hs.columns = [i.lower() for i in all_hs.columns]\n",
    "\n",
    "# Make hsgraddte into datetime object\n",
    "all_hs['hsgraddte'] = pd.to_datetime(all_hs['hsgraddte'])\n",
    "\n",
    "# Make year column for hs grad date\n",
    "all_hs['hs_grad_yr'] = all_hs['hsgraddte'].dt.year.fillna(0).astype(int)\n",
    "\n",
    "# Convert term to string to extract term_year\n",
    "all_hs['term'] = all_hs['term'].astype(str)\n",
    "\n",
    "all_hs['term_year'] = [all_hs['term'][i][:4] for i in range(len(all_hs))]\n",
    "\n",
    "all_hs['term_year'] = all_hs['term_year'].astype(int)\n",
    "\n",
    "# Identify which students enrolled in the Fall right after HS Graduation\n",
    "all_hs['hs_matriculation'] = ['From HS' if  i == j else 'Not From HS' for i, j in zip(all_hs['term_year'], all_hs['hs_grad_yr'])]\n",
    "\n",
    "hs_matriculation = (pd.DataFrame(all_hs.groupby(['term', 'hs_matriculation'])['id'].count())\n",
    "                      .reset_index(drop = False)\n",
    "                      .rename(columns = {'id':'cnt'})\n",
    "                   )\n",
    "\n",
    "hs_matriculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge enrolled_gpas_online_fafsa with all_hs[['id', 'term', 'hs_matriculation']]\n",
    "all_hs_for_merge = all_hs[['id', 'term', 'hs_matriculation']]\n",
    "all_hs_for_merge['term'] = all_hs_for_merge['term'].astype(int)\n",
    "\n",
    "enrolled_gpas_online_fafsa_hs = (enrolled_gpas_online_fafsa.merge(all_hs_for_merge, how = 'left', on = ['id', 'term'])\n",
    "                                    .drop_duplicates(subset = ['id', 'term'])\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure I didn't lose any students unnecessarily in the merge. \n",
    "# For some reason, the merge created a few dozen additional lines, which is why\n",
    "# I had to add 'drop_duplicates' to it. Therefore, I am making sure I am left \n",
    "# with the original set of students I wanted to have.\n",
    "df1 = enrolled_gpas_online_fafsa[['term', 'id']]\n",
    "df2 = enrolled_gpas_online_fafsa_hs[['term', 'id']]\n",
    "\n",
    "# Sort both DataFrames by their columns and reset their indices\n",
    "df1_sorted = df1.sort_values(by=['term', 'id']).reset_index(drop=True)\n",
    "df2_sorted = df2.sort_values(by=['term', 'id']).reset_index(drop=True)\n",
    "\n",
    "if df1_sorted.equals(df2_sorted):\n",
    "    print(\"The DataFrames are the same.\")\n",
    "else:\n",
    "    print(\"The DataFrames are different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorient columns\n",
    "enrolled_gpas_online_fafsa_hs = enrolled_gpas_online_fafsa_hs[['term', 'pidm', 'age', 'id', 'totcr', 'status', 'stype', 'resd_desc',\n",
    "                                   'degcode', 'majr_desc1', 'gender', 'ethn_desc', 'cnty_desc1', 'styp',\n",
    "                                   'resd', 'acd_std_desc', 'term_att_crhr', 'term_earn_crhr', 'term_gpa',\n",
    "                                   'inst_gpa', 'inst_earned', 'inst_hrs_att', 'overall_gpa',\n",
    "                                   'fully_online', 'no_pell', 'pell', 'subsidized', 'unsubsidized',\n",
    "                                   'summer_plus', 'kansas_promise', 'all_fafsa', 'hs_matriculation', 'enrolled']]\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553db5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrolled_gpas_online_fafsa_hs.to_csv('FA19 - FA23 Cleaned Dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ced78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store enrolled_gpas_online_fafsa_hs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
